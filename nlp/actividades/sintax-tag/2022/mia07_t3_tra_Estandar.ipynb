{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universidad Internacional de La Rioja (UNIR) - Máster Universitario en Inteligencia Artificial - Procesamiento del Lenguaje Natural** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Datos del alumno (Nombre y Apellidos):\n",
    "\n",
    "Fecha:\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20pt; font-weight: bold; color: #0098cd;\">Trabajo: Etiquetado morfosintáctico</span>\n",
    "\n",
    "**Objetivos** \n",
    "\n",
    "Con esta actividad se tratará de que el alumno consiga aplicar un método basado en modelos ocultos de Markov (HMM) para realizar el etiquetado morfosintáctico de una oración.\n",
    "\n",
    "**Descripción**\n",
    "\n",
    "En esta actividad debes implementar en Python un etiquetador morfosintáctico basado en modelos ocultos de Markov (HMM) y realizar el etiquetado morfosintáctico de la oración:\n",
    "\n",
    "> *Habla con el enfermo grave de trasplantes.*\n",
    "\n",
    "Implementando también en Python el algoritmo de Viterbi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Parte 1: Construir el etiquetador morfosintáctico</span>\n",
    "\n",
    "En esta primera parte de la actividad tienes que implementar en Python el etiquetador morfosintáctico basado en un HMM bigrama a partir de un corpus etiquetado.\n",
    "\n",
    "***\n",
    "Para ello debes utilizar el corpus mia07_t3_tra_Corpus-tagged, que se encuentra disponible en el aula virtual.\n",
    "***\n",
    "\n",
    "El corpus se compone de frases en español etiquetadas con conocimiento sobre las partes de la oración (categorías gramaticales o POS tags). Estas frases etiquetadas han sido extraídas de algunos documentos que forman parte de Wikicorpus, un corpus trilingüe (español, catalán e inglés) compuesto por más de 750 millones de palabras. Wikicorpus fue creado por investigadores de la Universitat Politèncnica de Catalunya a partir de documentos de la Wikipedia que fueron anotados con la librería opensource FreeLing.\n",
    "\n",
    "La tabla 1 muestra en formato de texto plano y sin etiquetar algunos ejemplos de frases que componen el corpus. De hecho, también se indica el identificador del documento del cual han sido extraídas las frases etiquetadas.\n",
    "\n",
    "La versión anotada la conforma el corpus anotado proporcionado para realizar esta actividad. El formato del fichero de texto que contiene el corpus es el mismo que el utilizado en Wikicorpus. Por lo tanto, cada uno de los documentos de Wikipedia se identifica con el tag XML <doc> donde se indica el identificador del documento (id). \n",
    "    \n",
    "Además, cada una de las frases en el documento viene separada por una línea en blanco. La información relativa a cada palabra de la frase se representa en una nueva línea del fichero. Para cada palabra, es decir, en cada línea del fichero, se proporciona —además del token que representa a la propia palabra— su lema, la etiqueta gramatical (POS tag) asociada a la palabra y el sentido de esta. \n",
    "\n",
    "La figura 1 muestra una captura del corpus anotado, donde se observa la frase «Tristana es una película del director español nacionalizado mexicano Luis Buñuel.» perteneciente al documento de Wikicorpus con identificador 27315 y titulado Tristana.\n",
    "\n",
    "Si se analizan las anotaciones para la palabra «es», se observa que su lema es «ser», que la categoría gramatical a la que pertenece esa palabra es la identificada por la etiqueta gramatical «VSIP3S0» y que el sentido de la palabra es el identificado por el código «01775973175».\n",
    "\n",
    "También se observa que la palabra «del» en la frase se representa en dos líneas y se anota con dos tokens, el primero «de» y el segundo «el». Esto se debe a que la palabra «del» es la contracción de la preposición «de» y el artículo «el». Por el contrario, el nombre propio «Luis Buñuel», que está formado por dos palabras (el nombre «Luis» y el apellido «Buñuel»), se anota como un único token «luis_buñuel». Además, se observa que el punto final de la frase también viene anotado como un token «.».\n",
    "\n",
    "Aunque el corpus anotado proporciona más información (ver figura 1), es importante tener en cuenta de que para realizar esta actividad solo será necesario el token y la etiqueta gramatical (POS tag) de cada palabra; es decir, la información contenida en la primera y la tercera cadena de cada línea que representa una palabra en el corpus anotado. \n",
    "\n",
    "Las etiquetas gramaticales (POS tags) utilizadas para anotar la información morfosintáctica del corpus son las definidas en FreeLing y se basan en EAGLES, una recomendación para la anotación de la mayoría de las lenguas europeas. La definición del conjunto de etiquetas gramaticales (POS tags) utilizadas por FreeLing en el etiquetado de un corpus en español se puede consultar en la web.\n",
    "\n",
    "***\n",
    "Accede al recurso a través del aula virtual o desde la siguiente dirección web:\n",
    "https://freeling-user-manual.readthedocs.io/en/v4.1/tagsets/tagset-es/\n",
    "***\n",
    "\n",
    "Las etiquetas gramaticales de EAGLES utilizadas por FreeLing son de longitud variable, donde cada carácter corresponde a una característica morfosintáctica. El primer carácter en la etiqueta es siempre la categoría gramatical o parte de la oración. Esa categoría gramatical determina la longitud de la etiqueta y la interpretación de cada uno del resto de caracteres en la misma. \n",
    "\n",
    "La definición de la etiqueta para la categoría gramatical «verbo» se muestra en la tabla 2. Entonces, la etiqueta «VSIP3S0», con la que ha sido etiquetada la palabra «es» en la frase que se presentó anteriormente, se interpreta de la siguiente forma: se refiere a un verbo (V) de tipo semiauxiliar (S) en modo indicativo (I) y en tiempo presente (P) para la tercera persona (3) de (número) singular (S). Asimismo, el carácter «0» al final de la etiqueta indica que esta forma verbal no tiene género.\n",
    "\n",
    "Es importante destacar que para realizar la actividad se deben utilizar las etiquetas con las que se anota el corpus en formato EAGLES; por ejemplo, «VSIP3S0». \n",
    "\n",
    "**Importante:** Si se utilizan otras etiquetas la actividad será considerada incorrecta y puntuada con cero puntos.\n",
    "\n",
    "Para construir el etiquetador morfosintáctico a partir del corpus etiquetado con los datos de entrenamiento, deberás seguir los siguientes pasos:\n",
    "\n",
    "* Cargar el corpus para extraer la primera y tercera columna de cada registro.\n",
    "* Calcular las probabilidades que rigen el HMM bigrama, es decir:\n",
    "    - Calcular las probabilidades de emisión del HMM a partir del corpus etiquetado.\n",
    "    - Calcular las probabilidades de transición del HMM a partir del corpus etiquetado.\n",
    "\n",
    "**Nota:** Presenta en el envío de la actividad la tabla (guardada en formato de hoja de cálculo de Microsoft Excel (.xlsx) o equivalente) con las probabilidades de emisión y las de transición, calculadas para todas las etiquetas y tokens (palabras) que aparecen en el corpus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar el corpus para extraer la primera y tercera columna de cada registro\n",
    "\n",
    "En primer lugar se va a cargar el corpus leyendo el archivo y recuperando la información de la _primera_ y _tercera_ columna de cada registro que continen el _token_ de la palabra y la _etiqueta_, respectivamente.\n",
    "\n",
    "Estos valores se almacenarán en objetos de la clase `Palabra`.\n",
    "\n",
    "Esta clase permitirá recuperar el `Token()` y el `Tag()` fácilmente para cada registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Palabra:\n",
    "    '''\n",
    "    Clase para guardar el token y la etiqueta de una palabra de un corpus\n",
    "    '''\n",
    "\n",
    "    def __init__(self, token: str, tag: str):\n",
    "        '''\n",
    "        Constructor de la clase\n",
    "\n",
    "        token : str\n",
    "            Token de la palabra\n",
    "\n",
    "        tag : str\n",
    "            Etiqueta de la palabra\n",
    "        '''\n",
    "        self._token = token\n",
    "        self._tag = tag\n",
    "\n",
    "    def Token(self):\n",
    "        '''\n",
    "        Método para acceder al token de la palabra\n",
    "        '''\n",
    "        return self._token\n",
    "\n",
    "    def Tag(self):\n",
    "        '''\n",
    "        Método par acceder a la etiqueta de la palabra\n",
    "        '''\n",
    "        return self._tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El corpus se guardará como una lista que a su vez contiene una serie de listas de objetos del tipo `Palabra`. Cada una de las listas de objetos del tipo `Palabra` guarda una oración. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = open('mia07_t3_tra_Corpus-tagged.txt', \"r\")\n",
    "\n",
    "corpus = list()\n",
    "oracion_actual = list()\n",
    "\n",
    "for entrada in archivo.readlines():\n",
    "    entrada = entrada.split()\n",
    "    if len(entrada) == 0:\n",
    "        # Puede ser la primera oración del documento\n",
    "        # O que termina la oración\n",
    "        if len(oracion_actual) > 0:\n",
    "            # Fin de la oración\n",
    "            corpus.append(oracion_actual)\n",
    "        oracion_actual = list()\n",
    "        continue\n",
    "\n",
    "    elif entrada[0] == '<doc':\n",
    "        # Inicio de documento. No se hace nada\n",
    "        continue\n",
    "\n",
    "    elif entrada[0] == '</doc>':\n",
    "        # Fin del documento. No se hace nada\n",
    "        continue\n",
    "  \n",
    "    oracion_actual.append(Palabra(token=entrada[0], tag=entrada[2]))\n",
    "\n",
    "archivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código te permite imprimir el corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for oracion in corpus:\n",
    "    for palabra in oracion:\n",
    "        print(palabra.Token(), palabra.Tag())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular las probabilidades que rigen el HMM bigrama\n",
    "\n",
    "Una vez se dispone del `corpus` correctamente cargado se creará un objeto, `hmmbigrama` de la clase `HMMBigrama`.\n",
    "\n",
    "`hmmbigrama` permitirá hacer el cálculo de las tablas de probabilidades de transición y de emisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se usa pandas para crear las tablas.\n",
    "import pandas as pd\n",
    "\n",
    "class HMMBigrama:\n",
    "    '''\n",
    "    Clase para obtener las matrices de probabilidad HMM Bigrama a partir de un corpus\n",
    "    '''\n",
    "\n",
    "    def __init__(self, corpus: [[Palabra]]):\n",
    "        '''\n",
    "        Constructor de la clase para calcular el Modelo Oculto de Markov Bigrama\n",
    "        '''\n",
    "        self._corpus = corpus\n",
    "        self._estados = dict()\n",
    "        self._tokens = dict()\n",
    "        self._q0 = 'q0'\n",
    "        self._qF = 'qF'\n",
    "\n",
    "        self._prob_trans = pd.DataFrame()\n",
    "        self._prob_obs = pd.DataFrame()\n",
    "\n",
    "    def Corpus(self):\n",
    "        return self._corpus.copy()\n",
    "\n",
    "    def EstadoInicial(self):\n",
    "        return self._q0\n",
    "\n",
    "    def EstadoFinal(self):\n",
    "        return self._qF\n",
    "\n",
    "    def _ProcesarCorpus(self):\n",
    "        '''\n",
    "        Método para contar el número de ocurrencias de estados y tokens\n",
    "        '''\n",
    "        for oracion in self._corpus:\n",
    "            for palabra in oracion:\n",
    "                            \n",
    "                # Se recorren todas las palabras de todas las oraciones del corpus recuperando las etiquetas (estados)\n",
    "                estado = palabra.Tag()\n",
    "                estados = self._estados\n",
    "                estados[estado] = estados[estado] + 1 if estado in estados else 1\n",
    "\n",
    "                # Se recorren todas las palabras de todas las oraciones del corpus recuperando los tokens\n",
    "                token = palabra.Token()\n",
    "                tokens = self._tokens\n",
    "                tokens[token] = tokens[token] + 1 if token in tokens else 1\n",
    "                \n",
    "\n",
    "    def Estados(self, incluir_inicial: bool = False, incluir_final: bool = False):\n",
    "        '''\n",
    "        Devuelve los estados del bigrama en base al corpus proporcionado al constructor\n",
    "\n",
    "        incluir_inicial : bool (False)\n",
    "            Flag para indicar si se quiere recuperar el estado inicial\n",
    "\n",
    "        incluir_final : bool (False)\n",
    "            Flag para indicar si se quiere recuperar el estado final\n",
    "\n",
    "        return\n",
    "            Diccionario de estados con el número de ocurrencias de cada estado en el corpus\n",
    "        '''\n",
    "\n",
    "        if len(self._estados) == 0:\n",
    "            self._ProcesarCorpus()\n",
    "\n",
    "        copia_estados = dict()\n",
    "        if incluir_inicial:\n",
    "            # Hay tantos estados como oraciones en el corpus\n",
    "            copia_estados[self._q0] = len(self._corpus)\n",
    "\n",
    "        copia_estados.update(self._estados)\n",
    "\n",
    "        if incluir_final:\n",
    "            # Hay tantos estados como oraciones en el corpus\n",
    "            copia_estados[self._qF] = len(self._corpus)\n",
    "\n",
    "        return copia_estados\n",
    "\n",
    "    def Tokens(self):\n",
    "        '''\n",
    "        Devuelve los tokens del bigrama en base al corpus proporcionado al constructor\n",
    "\n",
    "        return\n",
    "            Diccionario de tokens con el número de ocurrencias de cada token en el corpus\n",
    "        '''\n",
    "\n",
    "        if len(self._tokens) == 0:\n",
    "            self._ProcesarCorpus()\n",
    "\n",
    "        return self._tokens.copy()\n",
    "\n",
    "    \n",
    "    def ProbabilidadesDeTransicion(self):\n",
    "        '''\n",
    "        Método para calcular las probabilidades de transición bigrama\n",
    "        a partir del corpus proporcionado a la clase\n",
    "        '''\n",
    "\n",
    "        # Si ya se ha calculado se devuelve\n",
    "        if len(self._prob_trans) != 0:\n",
    "            return self._prob_trans.copy()\n",
    "\n",
    "        '''\n",
    "        En esta parte del código se calcula el número de\n",
    "        transiciones bigrama, es decir, en el diccionario\n",
    "        'contador_transiciones' se almacenarán los contadores\n",
    "        de las transiciones t-1 -> t\n",
    "\n",
    "        Las claves del diccionario serán los estados de partida\n",
    "        mientras que los valores de cada clave serán los estados\n",
    "        de destino y el número de veces que transitan a cada estado\n",
    "        '''\n",
    "        q0 = self._q0\n",
    "        qF = self._qF\n",
    "        contador_transiciones = {q0: dict()}\n",
    "\n",
    "        for oracion in self._corpus:\n",
    "            # Contador de transición q0 a estado q1\n",
    "            q1 = oracion[0].Tag()\n",
    "            if q1 not in contador_transiciones[q0]:\n",
    "                contador_transiciones[q0][q1] = 0\n",
    "            contador_transiciones[q0][q1] += 1\n",
    "\n",
    "            # Contador de transiciones entre palabras de la oración\n",
    "            for it in range(0, len(oracion) - 1):\n",
    "                \n",
    "            ##################################################  \n",
    "            ########## Aquí debes incluir tu código ##########  \n",
    "            ##################################################\n",
    "\n",
    "            \n",
    "            # Contador de transición qF_1 a qF\n",
    "            qF_1 = oracion[-1].Tag()\n",
    "\n",
    "            if qF_1 not in contador_transiciones:\n",
    "                contador_transiciones[qF_1] = dict()\n",
    "            if qF not in contador_transiciones[qF_1]:\n",
    "                contador_transiciones[qF_1][qF] = 0\n",
    "\n",
    "            contador_transiciones[qF_1][qF] += 1\n",
    "            \n",
    "        '''\n",
    "        Cálculo de la tabla de probabilidades de transición.\n",
    "\n",
    "        Se calculan ahora las probabilidades de transición\n",
    "        siguiendo la relación: P(T|T-1) = C(T-1, T) / C(T-1).\n",
    "\n",
    "        En 'contador_transiciones' se han acumulado la coincidencias C(T-1, T)\n",
    "        y en 'estados' se tiene disponible C(T-1) por lo que es posible\n",
    "        calcular la tabla de probabilidades de transiciones con estos elementos.\n",
    "        '''\n",
    "        tags_estados_iniciales = list(\n",
    "            self.Estados(incluir_inicial=True).keys())\n",
    "        tags_estados_finales = list(self.Estados(incluir_final=True).keys())\n",
    "        estados_totales = self.Estados(\n",
    "            incluir_inicial=True, incluir_final=True)\n",
    "\n",
    "        prob_trans = {qt_1: {qt: 0 for qt in tags_estados_finales}\n",
    "                      for qt_1 in tags_estados_iniciales}\n",
    "        for qt_1 in tags_estados_iniciales:\n",
    "            for qt in tags_estados_finales:\n",
    "                prob = 0\n",
    "                if qt_1 in contador_transiciones and qt in contador_transiciones[qt_1]:\n",
    "                    \n",
    "                    ##################################################  \n",
    "                    ########## Aquí debes incluir tu código ##########  \n",
    "                    ##################################################\n",
    "                    \n",
    "                prob_trans[qt_1][qt] = prob\n",
    "\n",
    "        self._prob_trans = pd.DataFrame.from_dict(prob_trans, orient='index')\n",
    "\n",
    "        return self._prob_trans.copy()\n",
    "\n",
    "    def ProbabilidadesDeEmision(self):\n",
    "        '''\n",
    "        Método para calcular las probabilidades de emisión\n",
    "        a partir del corpus proporcionado a la clase\n",
    "        '''\n",
    "\n",
    "        if len(self._prob_obs) != 0:\n",
    "            return self._prob_obs.copy()\n",
    "\n",
    "        '''\n",
    "        En esta parte del código se calculan el número de\n",
    "        ocurrencias de la palabra Wi para la etiqueta Ti  \n",
    "        '''\n",
    "        estados = self.Estados()\n",
    "        contador_observaciones = {key: dict() for key in estados.keys()}\n",
    "\n",
    "        for oracion in self._corpus:\n",
    "            for palabra in oracion:\n",
    "                token = palabra.Token()\n",
    "                etiqueta = palabra.Tag()\n",
    "                if token not in contador_observaciones[etiqueta]:\n",
    "                                        \n",
    "                    ##################################################  \n",
    "                    ########## Aquí debes incluir tu código ##########  \n",
    "                    ##################################################\n",
    "\n",
    "                contador_observaciones[etiqueta][token] += 1\n",
    "\n",
    "        '''\n",
    "        Cálculo de la tabla de probabilidades de emisión.\n",
    "\n",
    "        Se calculan ahora las probabilidades de emisión\n",
    "        siguiendo la relación: P(Wi|Ti) = C(Ti,Wi) / C(Ti).\n",
    "\n",
    "        En 'contador_observaciones' se han acumulado la coincidencias C(Ti, Wi)\n",
    "        y en 'estados' se tiene disponible C(Ti) por lo que es posible\n",
    "        calcular la tabla de probabilidad de emisión con estos elementos.\n",
    "        '''\n",
    "        tokens = self.Tokens()\n",
    "        prob_obs = {Ti: {Wi: 0 for Wi in tokens} for Ti in estados}\n",
    "        for Ti in estados:\n",
    "            for Wi in tokens:\n",
    "                prob = 0\n",
    "                if Ti in contador_observaciones and Wi in contador_observaciones[Ti]:\n",
    "                                        \n",
    "                    ##################################################  \n",
    "                    ########## Aquí debes incluir tu código ##########  \n",
    "                    ##################################################\n",
    "                    \n",
    "                prob_obs[Ti][Wi] = prob\n",
    "\n",
    "        self._prob_obs = pd.DataFrame.from_dict(prob_obs, orient='index')\n",
    "\n",
    "        return self._prob_obs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código te permite crear el HMM Bigrama y obtener información relevante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmmbigrama = HMMBigrama(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmmbigrama.Tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hmmbigrama.Tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmmbigrama.Estados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hmmbigrama.Estados())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `ProbabilidadesDeTransición()` de la clase `HMMBigrama` devuelve la tabla de probabilidades de transición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_zero_green(val):\n",
    "    '''\n",
    "    Función para resaltar en verde las probabilidades que no sean 0\n",
    "    '''\n",
    "    return 'background-color: Aquamarine' if val > 0 else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob_transicion = hmmbigrama.ProbabilidadesDeTransicion()\n",
    "prob_transicion.style.applymap(non_zero_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_transicion.to_excel('mia07_t3_tra_resultados_trans.xlsx', sheet_name='prob_trans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `ProbabilidadesDeEmision()` de la clase `HMMBigrama` devuelve la tabla de probabilidades de emisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_emision = hmmbigrama.ProbabilidadesDeEmision()\n",
    "prob_emision.style.applymap(non_zero_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_emision.to_excel('mia07_t3_tra_resultados_emision.xlsx', sheet_name='prob_emision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Parte 2: Etiquetar morfosintácticamente una oración</span>\n",
    "\n",
    "En esta segunda parte de la actividad tienes que implementar en Python un programa que permita calcular la mejor secuencia de etiquetas para una oración, dicho de otro modo, realizar el etiquetado morfosintáctico de la oración: «Habla con el enfermo grave de trasplantes. ».\n",
    "\n",
    "Para ello debes utilizar el etiquetador que has construido en la parte 1 de esta actividad, es decir las tablas de probabilidades calculadas, y aplicar el algoritmo de Viterbi.\n",
    "\n",
    "Para aplicar el algoritmo de Viterbi, se deben seguir los siguientes pasos: \n",
    "\n",
    "* Calcular la matriz de probabilidades de la ruta se Viterbi (matriz con los valores de Viterbi) donde se representen claramente las observaciones y los estados de la máquina de estados finitos. Calcula el valor de Viterbi para cada celda de la matriz e indica claramente los valores obtenidos.\n",
    "Nota: Para simplificar, puedes eliminar todos aquellos estados asociados a etiquetas que no aparezcan en el posible análisis de la oración y sólo quedarte con los estados relevantes. Además, debes tener en cuenta la transición al estado final representado por el punto al final de la oración a analizar. \n",
    "\n",
    "* Obtener la ruta con máxima probabilidad, es decir, traza la ruta inversa para obtener la mejor secuencia de etiquetas. \n",
    "\n",
    "* Mostrar la oración etiquetada. Debes indicar claramente el resultado obtenido del etiquetado morfosintáctico de la oración estudiada.\n",
    "\n",
    "**Nota:** Presenta en el envío de la actividad la tabla (guardada en formato de hoja de cálculo de Microsoft Excel (.xlsx) o equivalente) con la matriz de probabilidades de la ruta Viterbi para el etiquetado morfosintáctico de la oración «Habla con el enfermo grave de trasplantes. ».\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular la matriz de probabilidades de la ruta de Viterbi\n",
    "\n",
    "La clase `Viterbi` permitirá realizar el cálculo de la matriz de probabilidades de la ruta de Viterbi y la posterior decodificación de la secuencia óptima de etiquetado para una oración a analizar.\n",
    "\n",
    "El etiquetado morfosintáctico creado en la Parte 1, es decir el objeto `hmmbigrama` de la clase `HMMBigrama`, será proporcionado al objeto `viterbi` de la clase `Viterbi` para poder aplicar el Algoritmo de Viterbi.\n",
    "\n",
    "El cálculo de los valores de Viterbi se realiza en el método `Probabilidades()` de la clase `Viterbi`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener la ruta con máxima probabilidad\n",
    "\n",
    "El método `DecodificacionSecuenciaOptima()` de la clase `Viterbi` permite obtener la secuencia de etiquetas más probables para la oración a analizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Viterbi:\n",
    "    '''\n",
    "    Algoritmo de Viterbi para obtener las mejores\n",
    "    etiquetas de las palabras de una oración\n",
    "    '''\n",
    "\n",
    "    def __init__(self, hmmbigrama: HMMBigrama, oracion: str):\n",
    "        self._hmmbigrama = hmmbigrama\n",
    "        self._oracion = oracion\n",
    "\n",
    "        self._estados_relevantes = None\n",
    "        self._prob_viterbi = pd.DataFrame()\n",
    "        self._estado_max_anterior = None\n",
    "\n",
    "    def _CalculoEstadosRelevantes(self):\n",
    "        self._estados_relevantes = set()\n",
    "        for palabra_analizar in [x.lower() for x in self._oracion.split()]:\n",
    "            # Búsqueda de estados\n",
    "            for oracion in self._hmmbigrama.Corpus():\n",
    "                for palabra_corpus in oracion:\n",
    "                    if palabra_corpus.Token() == palabra_analizar:\n",
    "                        self._estados_relevantes.add(palabra_corpus.Tag())\n",
    "\n",
    "    def Probabilidades(self):\n",
    "        if len(self._prob_viterbi) != 0:\n",
    "            return self._prob_viterbi.copy()\n",
    "\n",
    "        if not self._estados_relevantes:\n",
    "            self._CalculoEstadosRelevantes()\n",
    "\n",
    "        estados_relevantes = self._estados_relevantes\n",
    "\n",
    "        '''\n",
    "        Matriz en la que se guardan los valores de Viterbi\n",
    "        '''\n",
    "        matriz_viterbi = {q: dict() for q in estados_relevantes}\n",
    "\n",
    "        '''\n",
    "        Matriz asociada a la matriz de Viterbi en la que se almacena\n",
    "        el estado de origen que maximiza cada probabilidad\n",
    "        '''\n",
    "        self._estado_max_anterior = {q: dict() for q in estados_relevantes}\n",
    "\n",
    "        q0 = self._hmmbigrama.EstadoInicial()\n",
    "        prob_trans = self._hmmbigrama.ProbabilidadesDeTransicion()\n",
    "        prob_obs = self._hmmbigrama.ProbabilidadesDeEmision()\n",
    "\n",
    "        token_anterior = None\n",
    "        for token in [x.lower() for x in self._oracion.split()]:\n",
    "            for qDestino in estados_relevantes:\n",
    "\n",
    "                prob_max = 0\n",
    "                if not token_anterior:\n",
    "                    # Estado q0\n",
    "                    prob_max = prob_trans[qDestino][q0]\n",
    "                else:\n",
    "                    # Resto de estados\n",
    "                    for qOrigen in estados_relevantes:\n",
    "                        \n",
    "                        ##################################################  \n",
    "                        ########## Aquí debes incluir tu código ##########  \n",
    "                        ##################################################\n",
    "                        \n",
    "                        if prob_qOrigen > prob_max:\n",
    "                            \n",
    "                            ##################################################  \n",
    "                            ########## Aquí debes incluir tu código ##########  \n",
    "                            ##################################################\n",
    "\n",
    "                matriz_viterbi[qDestino][token] = prob_max * prob_obs[token][qDestino]\n",
    "\n",
    "            token_anterior = token\n",
    "\n",
    "        self._prob_viterbi = pd.DataFrame.from_dict(matriz_viterbi, orient='index')\n",
    "\n",
    "        return self._prob_viterbi.copy()\n",
    "\n",
    "    def DecodificacionSecuenciaOptima(self):\n",
    "        # Decodificación de la secuencia óptima\n",
    "        oracion_invertida = [x.lower() for x in self._oracion.split()]\n",
    "        oracion_invertida.reverse()\n",
    "\n",
    "        prob_viterbi = self.Probabilidades()\n",
    "\n",
    "        oracion_etiquetada = []\n",
    "        # Se busca la probablidad máxima de Viterbi asociada a la última palabra de la oración\n",
    "        palabra = oracion_invertida[0]\n",
    "        etiqueta = prob_viterbi[palabra].idxmax()\n",
    "        oracion_etiquetada.append({'token': palabra, 'tag': etiqueta, 'prob': prob_viterbi[palabra].max()})\n",
    "\n",
    "        # Ahora se usa la tabla auxiliar de Viterbi que contiene\n",
    "        # el estado de origen que maximiza cada probabilidad Viterbi\n",
    "        palabra_anterior = palabra\n",
    "        for palabra in oracion_invertida[1:]:\n",
    "            \n",
    "            ##################################################  \n",
    "            ########## Aquí debes incluir tu código ##########  \n",
    "            ##################################################\n",
    "\n",
    "        # Se recupera el orden de la oración con las palabras ya etiquetadas\n",
    "        oracion_etiquetada.reverse()\n",
    "\n",
    "        return oracion_etiquetada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código te permite realizar el análisis de la oración: \"Habla con el enfermo grave de trasplantes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi = Viterbi(hmmbigrama=hmmbigrama, oracion='Habla con el enfermo grave de trasplantes .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código te permite mostrar la matriz de probabilidades de la ruta de Viterbi (solo se presentan aquellas etiquetas que tienen algún valor no nulo para alguna de las palabras de la oración analizada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_prob_viterbi = viterbi.Probabilidades()\n",
    "matriz_prob_viterbi.style.applymap(non_zero_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_prob_viterbi.to_excel('mia07_t3_tra_resultados_viterbi.xlsx', sheet_name='viterbi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código te permite mostrar la ruta de Viterbi con máxima probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracion_etiquetada = viterbi.DecodificacionSecuenciaOptima()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracion_etiquetada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar la oración etiquetada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código te permite mostrar la oración etiquetada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for palabra in oracion_etiquetada:\n",
    "    print('{} / {}'.format(palabra['token'], palabra['tag']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Parte 3: Analizar el etiquetador morfosintáctico</span>\n",
    "\n",
    "Una vez hayas creado el etiquetador morfosintáctico y lo hayas utilizado para etiquetar la oración «Habla con el enfermo grave de trasplantes.», reflexiona sobre los resultados obtenidos, interprétalos y analiza el rendimiento del etiquetador creado y sus limitaciones. Para ello responde de forma razonada a las siguientes preguntas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Es correcto el etiquetado morfosintáctico que has obtenido? Indica por qué."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## Aquí debes indicar tu respuesta ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Indica el resultado de etiquetar la oración «El enfermo grave habla de trasplantes.» utilizando el etiquetador morfosintáctico. ¿Es correcto el etiquetado morfosintáctico que has obtenido? Indica por qué."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## Aquí debes indicar tu respuesta ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cuáles son las limitaciones del analizador morfosintáctico que has creado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## Aquí debes indicar tu respuesta ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Qué posibles mejoras se podrían aplicar para mejorar el rendimiento del etiquetador morfosintáctico creado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## Aquí debes indicar tu respuesta ##########"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
