{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecurrentNeuralNetworks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0U3A4492rm0"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL7elQHL34Ek"
      },
      "source": [
        "MAX_LEN = 100\n",
        "EMBEDDING_DIM = 10\n",
        "LSTM_SIZE = 250\n",
        "NUM_CLASSES = 5\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 16"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgUR735t3oX2"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_LEN, EMBEDDING_DIM, trainable=True))\n",
        "model.add(LSTM(LSTM_SIZE, return_sequences=True))\n",
        "model.add(LSTM(LSTM_SIZE, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(NUM_CLASSES + 1, activation='softmax')))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])                        \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKkS0ZtZ6o7A"
      },
      "source": [
        "texts = [\"Él vino con el vino\"] * 100\n",
        "labels = [[\"PRON\", \"VERB\", \"PREP\", \"DET\", \"NOUN\" ]] * 100\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "labels_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "labels_tokenizer.fit_on_texts(labels)\n",
        "X = np.array(tokenizer.texts_to_sequences(texts))\n",
        "y = np.reshape(labels_tokenizer.texts_to_sequences(labels), (len(labels), -1, 1))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgEfmb139SBH"
      },
      "source": [
        "model.fit(x=X, y=y_sparse, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbx4bIOjBeVC"
      },
      "source": [
        "text = 'Él vino con el vino'\n",
        "X = np.array(tokenizer.texts_to_sequences([text]))\n",
        "p = model.predict(X)\n",
        "print(p.shape)\n",
        "\n",
        "tags = labels_tokenizer.sequences_to_texts(\n",
        "    [[x.index(max(x))] for x in p[0].tolist()]\n",
        "    )\n",
        "print(tags)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}